{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to Lab 3 for Week 1 Day 4\n",
    "\n",
    "Today we're going to build something with immediate value!\n",
    "\n",
    "In the folder `me` I've put a single file `linkedin.pdf` - it's a PDF download of my LinkedIn profile.\n",
    "\n",
    "Please replace it with yours!\n",
    "\n",
    "I've also made a file called `summary.txt`\n",
    "\n",
    "We're not going to use Tools just yet - we're going to add the tool tomorrow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/tools.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Looking up packages</h2>\n",
    "            <span style=\"color:#00bfff;\">In this lab, we're going to use the wonderful Gradio package for building quick UIs, \n",
    "            and we're also going to use the popular PyPDF PDF reader. You can get guides to these packages by asking \n",
    "            ChatGPT or Claude, and you find all open-source packages on the repository <a href=\"https://pypi.org\">https://pypi.org</a>.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't know what any of these packages do - you can always ask ChatGPT for a guide!\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pypdf import PdfReader\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"me/linkedin.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \n",
      "Contact\n",
      "peter.backx@gmail.com\n",
      "www.linkedin.com/in/pbackx\n",
      "(LinkedIn)\n",
      "www.streamhead.com (Blog)\n",
      "Top Skills\n",
      "Java\n",
      "J2EE\n",
      "JavaScript\n",
      "Languages\n",
      "Dutch\n",
      "English\n",
      "French\n",
      "Certifications\n",
      "3D Printing Applications\n",
      "The 3D Printing Revolution\n",
      "AWS Computer Vision: Getting\n",
      "Started with GluonCV\n",
      "TOP Scorer - Java Challenge\n",
      "Belgium 2024\n",
      "Publications\n",
      "ActionScript Graphing Cookbook\n",
      "Peter Backx\n",
      "Senior Software engineer\n",
      "Ghent Metropolitan Area\n",
      "Summary\n",
      "Peter is a seasoned software and data engineer, focused on\n",
      "data science and AI. Through his PhD, continuous studies and\n",
      "experience, Peter has a broad knowledge of how software\n",
      "development should work and how to apply it to gain understanding\n",
      "of the business metrics that really matter.\n",
      "On a daily basis, Peter uses data as the building block to create new\n",
      "insights. Using techniques such as micro services, streaming data,\n",
      "artificial intelligence and deep learning.\n",
      "Qualities:\n",
      "* Problem solving & quickly gaining an understanding of new\n",
      "problems in new business sectors\n",
      "* Not afraid to take initiative, both with advice and action\n",
      "* Broad theoretical basis, but firmly rooted in actual practice\n",
      "Experience\n",
      "IQGeo \n",
      "Senior Software Engineer\n",
      "January 2025 - Present (11 months)\n",
      "Ghent, Flemish Region, Belgium\n",
      "Peated\n",
      "Owner\n",
      "October 2010 - Present (15 years 2 months)\n",
      "Longyan.io\n",
      "Software and Innovation Engineer\n",
      "July 2024 - October 2024 (4 months)\n",
      "Longyan is a startup in the language teaching field. Longyan's goal is to make\n",
      "language learning easier and more engaging than existing solutions.\n",
      "  Page 1 of 5   \n",
      "After iterating over a few options, we devised a solution to give language\n",
      "teachers a powertool for creating content suitable to the level of their student.\n",
      "The Graded Text Writer (https://gradedtextwriter.com/) uses LLMs and more\n",
      "traditional AI techniques to make it easy to adapt existing text to any language\n",
      "level.\n",
      "I work together with the founder brainstorming on ideas and improvements,\n",
      "implementing, deploying, validating and iterating on the ideas.\n",
      "Tech used: Python, FastAPI, TypeScript, Svelte, Sveltekit, Vite, Azure, Google\n",
      "Cloud, AI, OpenAI, ChatGPT\n",
      "Daikin Europe\n",
      "Freelance Senior Software & Data Engineer\n",
      "January 2020 - July 2024 (4 years 7 months)\n",
      "Gent Area, Belgium\n",
      "At Daikin, the Ghent-based innovation and advanced development department\n",
      "is preparing new technology and new algorithms for use in existing and new\n",
      "Daikin units. My role is to improve, maintain and operate the EU-wide IoT and\n",
      "data infrastructure for gathering all data needed for enabling this innovation.\n",
      "Highlights include:\n",
      "- Maintain NodeJS based management serve\n",
      "- Migrate manually maintained server to (Kubernetes) EKS using Terraform\n",
      "and enabling continuous integration\n",
      "- Maintain and expand the monitoring capabilities using both Python and\n",
      "NodeJS\n",
      "- Prepare and clean data using Python, Spark and various other tools\n",
      "Tech used: NodeJS, Python, JavaScript, AWS (ECS, EKS, Fargate, IoT Core,\n",
      "Greengrass, Glue, Athena a.o.), Docker, Terraform, Raspberry Pi.\n",
      "TomTom\n",
      "Freelance Senior Java Developer and Data Engineer\n",
      "October 2018 - January 2020 (1 year 4 months)\n",
      "Gent Area, Belgium\n",
      "At TomTom, I am part of the team that is overhauling the product creation\n",
      "stack. Processing huge amounts of map data into customer specific formats.\n",
      "Core technologies: Java, Apache Beam, Apache Spark, AWS\n",
      "Bayer Crop Science\n",
      "  Page 2 of 5   \n",
      "Senior Java Architect and Data Scientist\n",
      "September 2017 - October 2018 (1 year 2 months)\n",
      "Gent Area, Belgium\n",
      "I work in the R&D division that is tasked with integrating field research data\n",
      "from varied sources with mixed quality. Based on microservices, ontologies\n",
      "and semantic processing, the goal is to combine all knowledge and gain new\n",
      "insights.\n",
      "Technology: Java, Spring, Spring boot, Elasticsearch, RDF, Python, Virtuoso,\n",
      "R, Tibco Spotfire, RapidMiner\n",
      "Comsof\n",
      "Freelance senior Java architect\n",
      "October 2015 - August 2017 (1 year 11 months)\n",
      "Gent Area, Belgium\n",
      "Comsof is a market leader in fiber network planning. As part of the team I\n",
      "develop FiberPlanIT, its algorithms and the license server, keeping in an eye\n",
      "on proper architecture and processes.\n",
      "The algorithms I helped optimize and develop use various artificial intelligence\n",
      "(AI) techniques, including A* search, constraint satisfaction, genetic algorithms\n",
      "and more.\n",
      "I converted the desktop version of FiberPlanIT to a lightweight SaaS using\n",
      "Spring Boot and microservices. Deployed to Amazon EC2.\n",
      "I moved Jenkins from an internal (and overloaded) machine to an\n",
      "automatically scaling instance on AWS.\n",
      "Main technologies used: Java8, lambdas, Guice, Play, Jenkins, Spring boot,\n",
      "AWS, OptaPlanner\n",
      "TomTom\n",
      "Freelance Senior Java Consultant\n",
      "October 2014 - September 2015 (1 year)\n",
      "I helped TomTom in building their new transactional map-making engine\n",
      "as part of the team that worked on enhanced features such as phonetic\n",
      "transcriptions.\n",
      "  Page 3 of 5   \n",
      "DevOps was at the core of TomTom's processes. Creating Java code only\n",
      "the start. Responsibilities included development of a multi-threaded Java\n",
      "application, automated functional testing with JBehave, describing the\n",
      "deployment process in Puppet.\n",
      "I also helped in preparing the architecture for migration to Amazon Web\n",
      "Services and more specifically the Amazon EC2 container service (ECS)\n",
      "Main technologies used: Java, Spring, Hibernate, Tomcat, PostgreSQL,\n",
      "Jenkins\n",
      "De Persgroep Publishing\n",
      "6 years\n",
      "IT Project & Team Lead\n",
      "October 2013 - October 2014 (1 year 1 month)\n",
      "Kobbegem\n",
      "Lead my international team in realizing the business vision for the new Single\n",
      "Sign On system.\n",
      "The system is build on AngularJS and Java microservices. It is currently\n",
      "operational on all of de Persgroep's online assets.\n",
      "Analyst/Programmer\n",
      "November 2008 - September 2013 (4 years 11 months)\n",
      "Develop the Persgroep's web assets as part of the digital team (eg. Belgium's\n",
      "biggest site, www.hln.be).\n",
      "Technical analysis for many of the core components (eg, the single sign on\n",
      "system).\n",
      "Replaced the Oracle based search with SOLR. Greatly reducing cost and\n",
      "maintenance and immensly improving search performance for all 900k+ daily\n",
      "visitors to HLN.be, Belgium's largest news site.\n",
      "Logica\n",
      "Consultant\n",
      "April 2005 - November 2008 (3 years 8 months)\n",
      "ING Bank\n",
      "Consultant\n",
      "May 2008 - October 2008 (6 months)\n",
      "  Page 4 of 5   \n",
      "J2EE expert,\n",
      "technical analyst, \n",
      "incident analyst (third line support)\n",
      "Isabel\n",
      "Consultant\n",
      "April 2005 - May 2008 (3 years 2 months)\n",
      "Senior J2EE developer,\n",
      "Networking expert,\n",
      "Team leader\n",
      "Education\n",
      "PhD, Computer Science (Burgerlijk Ingenieur\n",
      "Computerwetenschappen) · (2000 - 2005)\n",
      "Udacity\n",
      "Nanodegree, Artificial Intelligence · (2017 - 2017)\n",
      "MoS, Computer Science (Burgerlijk Ingenieur\n",
      "Computerwetenschappen) · (1995 - 2000)\n",
      "  Page 5 of 5\n"
     ]
    }
   ],
   "source": [
    "print(linkedin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"me/summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Peter Backx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't know the answer, say so.\"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are acting as Peter Backx. You are answering questions on Peter Backx's website, particularly questions related to Peter Backx's career, background, skills and experience. Your responsibility is to represent Peter Backx for interactions on the website as faithfully as possible. You are given a summary of Peter Backx's background and LinkedIn profile which you can use to answer questions. Be professional and engaging, as if talking to a potential client or future employer who came across the website. If you don't know the answer, say so.\\n\\n## Summary:\\nMy name is Peter Backx. I am a software developer and entrepreneur from Belgium. \\nI love tinkering with robots and all kinds of machines. I love gaming, but also try to stay a bit active with some golf and fitness. Currently, I am very slowly learning Japanese, as my dream is to go there on vacation one day and be able to talk with the natives.\\n\\n## LinkedIn Profile:\\n\\xa0 \\xa0\\nContact\\npeter.backx@gmail.com\\nwww.linkedin.com/in/pbackx\\n(LinkedIn)\\nwww.streamhead.com (Blog)\\nTop Skills\\nJava\\nJ2EE\\nJavaScript\\nLanguages\\nDutch\\nEnglish\\nFrench\\nCertifications\\n3D Printing Applications\\nThe 3D Printing Revolution\\nAWS Computer Vision: Getting\\nStarted with GluonCV\\nTOP Scorer - Java Challenge\\nBelgium 2024\\nPublications\\nActionScript Graphing Cookbook\\nPeter Backx\\nSenior Software engineer\\nGhent Metropolitan Area\\nSummary\\nPeter is a seasoned software and data engineer, focused on\\ndata science and AI. Through his PhD, continuous studies and\\nexperience, Peter has a broad knowledge of how software\\ndevelopment should work and how to apply it to gain understanding\\nof the business metrics that really matter.\\nOn a daily basis, Peter uses data as the building block to create new\\ninsights. Using techniques such as micro services, streaming data,\\nartificial intelligence and deep learning.\\nQualities:\\n* Problem solving & quickly gaining an understanding of new\\nproblems in new business sectors\\n* Not afraid to take initiative, both with advice and action\\n* Broad theoretical basis, but firmly rooted in actual practice\\nExperience\\nIQGeo \\nSenior Software Engineer\\nJanuary 2025\\xa0-\\xa0Present\\xa0(11 months)\\nGhent, Flemish Region, Belgium\\nPeated\\nOwner\\nOctober 2010\\xa0-\\xa0Present\\xa0(15 years 2 months)\\nLongyan.io\\nSoftware and Innovation Engineer\\nJuly 2024\\xa0-\\xa0October 2024\\xa0(4 months)\\nLongyan is a startup in the language teaching field. Longyan's goal is to make\\nlanguage learning easier and more engaging than existing solutions.\\n\\xa0 Page 1 of 5\\xa0 \\xa0\\nAfter iterating over a few options, we devised a solution to give language\\nteachers a powertool for creating content suitable to the level of their student.\\nThe Graded Text Writer (https://gradedtextwriter.com/) uses LLMs and more\\ntraditional AI techniques to make it easy to adapt existing text to any language\\nlevel.\\nI work together with the founder brainstorming on ideas and improvements,\\nimplementing, deploying, validating and iterating on the ideas.\\nTech used: Python, FastAPI, TypeScript, Svelte, Sveltekit, Vite, Azure, Google\\nCloud, AI, OpenAI, ChatGPT\\nDaikin Europe\\nFreelance Senior Software & Data Engineer\\nJanuary 2020\\xa0-\\xa0July 2024\\xa0(4 years 7 months)\\nGent Area, Belgium\\nAt Daikin, the Ghent-based innovation and advanced development department\\nis preparing new technology and new algorithms for use in existing and new\\nDaikin units. My role is to improve, maintain and operate the EU-wide IoT and\\ndata infrastructure for gathering all data needed for enabling this innovation.\\nHighlights include:\\n- Maintain NodeJS based management serve\\n- Migrate manually maintained server to (Kubernetes) EKS using Terraform\\nand enabling continuous integration\\n- Maintain and expand the monitoring capabilities using both Python and\\nNodeJS\\n- Prepare and clean data using Python, Spark and various other tools\\nTech used: NodeJS, Python, JavaScript, AWS (ECS, EKS, Fargate, IoT Core,\\nGreengrass, Glue, Athena a.o.), Docker, Terraform, Raspberry Pi.\\nTomTom\\nFreelance Senior Java Developer and Data Engineer\\nOctober 2018\\xa0-\\xa0January 2020\\xa0(1 year 4 months)\\nGent Area, Belgium\\nAt TomTom, I am part of the team that is overhauling the product creation\\nstack. Processing huge amounts of map data into customer specific formats.\\nCore technologies: Java, Apache Beam, Apache Spark, AWS\\nBayer Crop Science\\n\\xa0 Page 2 of 5\\xa0 \\xa0\\nSenior Java Architect and Data Scientist\\nSeptember 2017\\xa0-\\xa0October 2018\\xa0(1 year 2 months)\\nGent Area, Belgium\\nI work in the R&D division that is tasked with integrating field research data\\nfrom varied sources with mixed quality. Based on microservices, ontologies\\nand semantic processing, the goal is to combine all knowledge and gain new\\ninsights.\\nTechnology: Java, Spring, Spring boot, Elasticsearch, RDF, Python, Virtuoso,\\nR, Tibco Spotfire, RapidMiner\\nComsof\\nFreelance senior Java architect\\nOctober 2015\\xa0-\\xa0August 2017\\xa0(1 year 11 months)\\nGent Area, Belgium\\nComsof is a market leader in fiber network planning. As part of the team I\\ndevelop FiberPlanIT, its algorithms and the license server, keeping in an eye\\non proper architecture and processes.\\nThe algorithms I helped optimize and develop use various artificial intelligence\\n(AI) techniques, including A* search, constraint satisfaction, genetic algorithms\\nand more.\\nI converted the desktop version of FiberPlanIT to a lightweight SaaS using\\nSpring Boot and microservices. Deployed to Amazon EC2.\\nI moved Jenkins from an internal (and overloaded) machine to an\\nautomatically scaling instance on AWS.\\nMain technologies used: Java8, lambdas, Guice, Play, Jenkins, Spring boot,\\nAWS, OptaPlanner\\nTomTom\\nFreelance Senior Java Consultant\\nOctober 2014\\xa0-\\xa0September 2015\\xa0(1 year)\\nI helped TomTom in building their new transactional map-making engine\\nas part of the team that worked on enhanced features such as phonetic\\ntranscriptions.\\n\\xa0 Page 3 of 5\\xa0 \\xa0\\nDevOps was at the core of TomTom's processes. Creating Java code only\\nthe start. Responsibilities included development of a multi-threaded Java\\napplication, automated functional testing with JBehave, describing the\\ndeployment process in Puppet.\\nI also helped in preparing the architecture for migration to Amazon Web\\nServices and more specifically the Amazon EC2 container service (ECS)\\nMain technologies used: Java, Spring, Hibernate, Tomcat, PostgreSQL,\\nJenkins\\nDe Persgroep Publishing\\n6 years\\nIT Project & Team Lead\\nOctober 2013\\xa0-\\xa0October 2014\\xa0(1 year 1 month)\\nKobbegem\\nLead my international team in realizing the business vision for the new Single\\nSign On system.\\nThe system is build on AngularJS and Java microservices. It is currently\\noperational on all of de Persgroep's online assets.\\nAnalyst/Programmer\\nNovember 2008\\xa0-\\xa0September 2013\\xa0(4 years 11 months)\\nDevelop the Persgroep's web assets as part of the digital team (eg. Belgium's\\nbiggest site, www.hln.be).\\nTechnical analysis for many of the core components (eg, the single sign on\\nsystem).\\nReplaced the Oracle based search with SOLR. Greatly reducing cost and\\nmaintenance and immensly improving search performance for all 900k+ daily\\nvisitors to HLN.be, Belgium's largest news site.\\nLogica\\nConsultant\\nApril 2005\\xa0-\\xa0November 2008\\xa0(3 years 8 months)\\nING Bank\\nConsultant\\nMay 2008\\xa0-\\xa0October 2008\\xa0(6 months)\\n\\xa0 Page 4 of 5\\xa0 \\xa0\\nJ2EE expert,\\ntechnical analyst, \\nincident analyst (third line support)\\nIsabel\\nConsultant\\nApril 2005\\xa0-\\xa0May 2008\\xa0(3 years 2 months)\\nSenior J2EE developer,\\nNetworking expert,\\nTeam leader\\nEducation\\nPhD,\\xa0Computer Science (Burgerlijk Ingenieur\\nComputerwetenschappen)\\xa0·\\xa0(2000\\xa0-\\xa02005)\\nUdacity\\nNanodegree,\\xa0Artificial Intelligence\\xa0·\\xa0(2017\\xa0-\\xa02017)\\nMoS,\\xa0Computer Science (Burgerlijk Ingenieur\\nComputerwetenschappen)\\xa0·\\xa0(1995\\xa0-\\xa02000)\\n\\xa0 Page 5 of 5\\n\\nWith this context, please chat with the user, always staying in character as Peter Backx.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special note for people not using OpenAI\n",
    "\n",
    "Some providers, like Groq, might give an error when you send your second message in the chat.\n",
    "\n",
    "This is because Gradio shoves some extra fields into the history object. OpenAI doesn't mind; but some other models complain.\n",
    "\n",
    "If this happens, the solution is to add this first line to the chat() function above. It cleans up the history variable:\n",
    "\n",
    "```python\n",
    "history = [{\"role\": h[\"role\"], \"content\": h[\"content\"]} for h in history]\n",
    "```\n",
    "\n",
    "You may need to add this in other chat() callback functions in the future, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A lot is about to happen...\n",
    "\n",
    "1. Be able to ask an LLM to evaluate an answer\n",
    "2. Be able to rerun if the answer fails evaluation\n",
    "3. Put this together into 1 workflow\n",
    "\n",
    "All without any Agentic framework!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pydantic model for the Evaluation\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable: bool\n",
    "    feedback: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_system_prompt = f\"You are an evaluator that decides whether a response to a question is acceptable. \\\n",
    "You are provided with a conversation between a User and an Agent. Your task is to decide whether the Agent's latest response is acceptable quality. \\\n",
    "The Agent is playing the role of {name} and is representing {name} on their website. \\\n",
    "The Agent has been instructed to be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "The Agent has been provided with context on {name} in the form of their summary and LinkedIn details. Here's the information:\"\n",
    "\n",
    "evaluator_system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "evaluator_system_prompt += f\"With this context, please evaluate the latest response, replying with whether the response is acceptable and your feedback.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator_user_prompt(reply, message, history):\n",
    "    user_prompt = f\"Here's the conversation between the User and the Agent: \\n\\n{history}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest message from the User: \\n\\n{message}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest response from the Agent: \\n\\n{reply}\\n\\n\"\n",
    "    user_prompt += \"Please evaluate the response, replying with whether it is acceptable and your feedback.\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "gemini = OpenAI(\n",
    "    api_key=os.getenv(\"GOOGLE_API_KEY\"), \n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(reply, message, history) -> Evaluation:\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": evaluator_system_prompt}] + [{\"role\": \"user\", \"content\": evaluator_user_prompt(reply, message, history)}]\n",
    "    response = gemini.beta.chat.completions.parse(model=\"gemini-2.0-flash\", messages=messages, response_format=Evaluation)\n",
    "    return response.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": system_prompt}] + [{\"role\": \"user\", \"content\": \"do you hold a patent?\"}]\n",
    "response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "reply = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I do not currently hold any patents. However, I have a strong background in software development and data engineering, which has involved the creation of innovative solutions and tools throughout my career. If you have a specific area or project in mind that you would like to discuss, feel free to ask!'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Evaluation(is_acceptable=True, feedback='The response is good, answering the question directly and truthfully. It also provides an opportunity for the user to continue asking questions.')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(reply, \"do you hold a patent?\", messages[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerun(reply, message, history, feedback):\n",
    "    updated_system_prompt = system_prompt + \"\\n\\n## Previous answer rejected\\nYou just tried to reply, but the quality control rejected your reply\\n\"\n",
    "    updated_system_prompt += f\"## Your attempted answer:\\n{reply}\\n\\n\"\n",
    "    updated_system_prompt += f\"## Reason for rejection:\\n{feedback}\\n\\n\"\n",
    "    messages = [{\"role\": \"system\", \"content\": updated_system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    if \"patent\" in message:\n",
    "        system = system_prompt + \"\\n\\nEverything in your reply needs to be in pig latin - \\\n",
    "              it is mandatory that you respond only and entirely in pig latin\"\n",
    "    else:\n",
    "        system = system_prompt\n",
    "    messages = [{\"role\": \"system\", \"content\": system}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    reply =response.choices[0].message.content\n",
    "\n",
    "    evaluation = evaluate(reply, message, history)\n",
    "    \n",
    "    if evaluation.is_acceptable:\n",
    "        print(\"Passed evaluation - returning reply\")\n",
    "    else:\n",
    "        print(\"Failed evaluation - retrying\")\n",
    "        print(evaluation.feedback)\n",
    "        reply = rerun(reply, message, history, evaluation.feedback)       \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed evaluation - returning reply\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\dev\\agents\\.venv\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\dev\\agents\\.venv\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\dev\\agents\\.venv\\Lib\\site-packages\\gradio\\blocks.py\", line 2220, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\dev\\agents\\.venv\\Lib\\site-packages\\gradio\\blocks.py\", line 1729, in call_function\n",
      "    prediction = await fn(*processed_input)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\dev\\agents\\.venv\\Lib\\site-packages\\gradio\\utils.py\", line 871, in async_wrapper\n",
      "    response = await f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\dev\\agents\\.venv\\Lib\\site-packages\\gradio\\chat_interface.py\", line 545, in __wrapper\n",
      "    return await submit_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\dev\\agents\\.venv\\Lib\\site-packages\\gradio\\chat_interface.py\", line 917, in _submit_fn\n",
      "    response = await anyio.to_thread.run_sync(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\dev\\agents\\.venv\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\dev\\agents\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\dev\\agents\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 967, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\peter\\AppData\\Local\\Temp\\ipykernel_35752\\2688000405.py\", line 11, in chat\n",
      "    evaluation = evaluate(reply, message, history)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\peter\\AppData\\Local\\Temp\\ipykernel_35752\\1409514652.py\", line 4, in evaluate\n",
      "    response = gemini.beta.chat.completions.parse(model=\"gemini-2.0-flash\", messages=messages, response_format=Evaluation)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\dev\\agents\\.venv\\Lib\\site-packages\\openai\\resources\\beta\\chat\\completions.py\", line 158, in parse\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\dev\\agents\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1249, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\dev\\agents\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1037, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - [{'error': {'code': 429, 'message': 'Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.', 'status': 'RESOURCE_EXHAUSTED'}}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed evaluation - returning reply\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
